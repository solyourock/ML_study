{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47167067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 정규표현식으로 해시태그를 제거해서 전처리 하는 것 보단 해시태그를 이용한 분석을 하는 것도 좋다고 생각함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a6d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import platform\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import swifter\n",
    "from konlpy.tag import Kkma, Komoran, Okt, Mecab\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f3a3971",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"그림 저장:\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48ede86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fontmanager():\n",
    "\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "    if platform.system() == 'Windows':\n",
    "        path = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "        font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "        rc('font', family=font_name)\n",
    "    elif platform.system() == 'Darwin':\n",
    "        path = '/Library/Fonts/Arial Unicode.ttf'\n",
    "        font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "        rc('font', family='AppleGothic')\n",
    "    elif platform.system() == 'Linux':\n",
    "        path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
    "        font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "        rc('font', family='NanumBarunGothic')\n",
    "    else:\n",
    "        print('Unknown system... sorry~~~~~~')\n",
    "    print(f\"해당 pc의 운영 체제는 {platform.system()}이며 {font_name}로 설정되었습니다\")  \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88dd3b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 pc의 운영 체제는 Darwin이며 Arial Unicode MS로 설정되었습니다\n"
     ]
    }
   ],
   "source": [
    "path = Fontmanager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "591136bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "election = pd.read_csv('dataset/election.csv')\n",
    "election = election.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf292f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "women_policy = pd.read_csv('dataset/women_policy.csv')\n",
    "# 혹시 모를 중복제거\n",
    "women_policy = women_policy.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4e0a91c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime    0\n",
       "id          0\n",
       "text        0\n",
       "username    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 혹시 모를 nan값 확인\n",
    "women_policy.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf0c4336",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = women_policy[women_policy['text'].apply(lambda x : x.startswith('#'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30fdff68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-671ba92bcac1>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  texts['text'] = texts['text'].str.split('\\n').apply(lambda x : [i for i in x if i.startswith('#') ])\n"
     ]
    }
   ],
   "source": [
    "texts['text'] = texts['text'].str.split('\\n').apply(lambda x : [i for i in x if i.startswith('#') ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4609063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-214d3dcda511>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  texts['text'] = texts['text'].apply(lambda x: ' '.join(x))\n"
     ]
    }
   ],
   "source": [
    "texts['text'] = texts['text'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0706e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-f50c97ac11a3>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  texts['text'] = texts['text'].str.split(' ').apply(lambda x : [i for i in x if i.startswith('#') ])\n"
     ]
    }
   ],
   "source": [
    "texts['text'] = texts['text'].str.split(' ').apply(lambda x : [i for i in x if i.startswith('#') ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2517b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordOfBag = sum(texts['text'], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7b9792e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#국민의힘은_여성탄압을_멈춰라</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#정권교체에_여성혐오_이용말라</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#이재명여성정책</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#변형카메라등록제</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#이재명_여성정책</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#여성이_뽑는다_여성이_바꾼다</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#대선토론</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#대선</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#페미니즘</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#여성정책</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>#휴머니즘</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#육아휴직</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>#구조적성차별</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>#여가부폐지</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>#이재명</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>#윤석열</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>#심상정</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>#대통령</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>#선거</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>#투표</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>#대통령선거</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>#연예</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>#씨리얼</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>#CReal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>#CBS뉴스</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>#언론사</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>#대안미디어</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>#인사이트</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index  0\n",
       "0   #국민의힘은_여성탄압을_멈춰라  1\n",
       "1   #정권교체에_여성혐오_이용말라  1\n",
       "2           #이재명여성정책  1\n",
       "3          #변형카메라등록제  1\n",
       "4          #이재명_여성정책  1\n",
       "5   #여성이_뽑는다_여성이_바꾼다  3\n",
       "6              #대선토론  1\n",
       "7                #대선  1\n",
       "8              #페미니즘  1\n",
       "9              #여성정책  1\n",
       "10             #휴머니즘  1\n",
       "11             #육아휴직  1\n",
       "12           #구조적성차별  1\n",
       "13            #여가부폐지  1\n",
       "14              #이재명  1\n",
       "15              #윤석열  1\n",
       "16              #심상정  1\n",
       "17              #대통령  1\n",
       "18               #선거  1\n",
       "19               #투표  1\n",
       "20            #대통령선거  1\n",
       "21               #연예  1\n",
       "22              #씨리얼  1\n",
       "23            #CReal  1\n",
       "24            #CBS뉴스  1\n",
       "25              #언론사  1\n",
       "26            #대안미디어  1\n",
       "27             #인사이트  1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(Counter(wordOfBag), orient='index').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c584f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "women_policy['text'][200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d381c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현식 이용한 전처리\n",
    "def clean(text):\n",
    "    #\\n 공백 제거\n",
    "    text = re.sub('\\n',' ',str(text))\n",
    "    # URL 제거\n",
    "    text = re.sub('https://[A-Za-z0-9./]*','',str(text))\n",
    "    # 한글자 제거 (ex:ㅋㅋ, ㅜㅜ)\n",
    "    text = re.sub('([ㄱ-ㅎㅏ-ㅣ])+', '', str(text))\n",
    "    # 숫자 제거 (숫자 + 숫자만 제거, ex: 1인가족)\n",
    "    text= re.sub('[0-9]{2}', '', str(text))\n",
    "    # @알파벳 제거 \n",
    "    text = re.sub('@[A-Za-z0-9./]*','',str(text))\n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777f78e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = women_policy['text'].apply(lambda x : clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08934fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test.apply(lambda x : x.startswith('#'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd0703",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96de244",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.apply(lambda x:x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21a8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "women_policy['text'] = women_policy['text'].apply(lambda x : clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77257263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어떤 유저가 가장 많이 트윗을 썻는지\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.barplot(x=women_policy['username'].value_counts()[:20].values, \n",
    "            y=women_policy['username'].value_counts()[:20].index,\n",
    "           orient='h')\n",
    "plt.title('Top 20 who the most writes', fontsize=20)\n",
    "plt.axvline(x=np.average(women_policy['username'].value_counts().values), color='b', linestyle='--', linewidth=3, \n",
    "            label='avg')\n",
    "plt.legend(fontsize=15)\n",
    "# save_fig('Top 20 who the most writes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efd2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 문장 길이 분포\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.distplot(a=women_policy['text'].str.len(), bins=70, kde=True,\n",
    "             kde_kws={\"color\":\"g\", \"alpha\":0.2, \"linewidth\":1, \"shade\":True})\n",
    "plt.title('text length distribution', fontsize=20)\n",
    "plt.axvline(x=np.average(women_policy['text'].str.len()), color='b', linestyle='--', linewidth=3, \n",
    "            label='avg')\n",
    "plt.legend(fontsize=15)\n",
    "# save_fig('text length distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1921e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "kkma = Kkma()\n",
    "komoran = Komoran()\n",
    "okt = Okt()\n",
    "mecab = Mecab()\n",
    "\n",
    "# stopwords list\n",
    "stop_words = pd.read_csv('dataset/한국어불용어100.txt', sep = \"\\t\", engine='python')\n",
    "stop_words = list(stop_words[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df94d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_words(words, k):\n",
    "    c = Counter(words)\n",
    "    cw = c.most_common(k)\n",
    "    return c, cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb222a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing(df, tokenizer):\n",
    "    nouns = df.swifter.apply(lambda x : tokenizer.nouns(x))\n",
    "    nouns_list = np.concatenate(nouns.tolist()).tolist()\n",
    "    words = [n for n in nouns_list if len(n) > 1] \n",
    "    return nouns_list, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a428a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords(words, stop_words):\n",
    "    words_new = []\n",
    "\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            words_new.append(word)\n",
    "    return words_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a88e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcloud(c):\n",
    "    wc = WordCloud(font_path='Arial Unicode', width=2000, height=1200, background_color ='white', scale=2.0, max_font_size=250)\n",
    "    gen = wc.generate_from_frequencies(c)\n",
    "    plt.figure(figsize = (12, 6), facecolor = None) \n",
    "    plt.imshow(gen)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    # save_fig(\"most_common_words_wordcloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649ea714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud\n",
    "nouns_list, words = tokenizing(women_policy['text'], okt)\n",
    "words_new = stopwords(words, stop_words)\n",
    "c, cw = common_words(words_new, 200)\n",
    "wordcloud(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2204b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 길이 분포\n",
    "nouns = women_policy['text'].swifter.apply(lambda x : okt.nouns(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8149453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.distplot(a=nouns.str.len(), bins=30, kde=True,\n",
    "             kde_kws={\"color\":\"g\", \"alpha\":0.2, \"linewidth\":1, \"shade\":True})\n",
    "plt.title('word length distribution', fontsize=20)\n",
    "plt.axvline(x=nouns.str.len().mean(), color='b', linestyle='--', linewidth=3, \n",
    "            label='avg')\n",
    "plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c4ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopword 단어 분포\n",
    "\n",
    "def stopwords(words, stop_words):\n",
    "    words_new = []\n",
    "\n",
    "    for word in words:\n",
    "        if word in stop_words:\n",
    "            words_new.append(word)\n",
    "    return words_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9bc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 사전에 '여자' 등의 단어가 포함되어 있어서 뺐음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8853acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_new = stopwords(words, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47983c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.countplot(words_new)\n",
    "plt.title('stopword distribution', fontsize=20)\n",
    "plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d236007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram exploration\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ba04b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = women_policy['text'].str.split()\n",
    "new = new.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39327ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [n for n in new if len(n) > 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449e4946",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = sum(words, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124898a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(2,2)).fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = vec.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c6775",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_words = bag_of_words.sum(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d53cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_freq = [(word, sum_words[0, idx])  for word, idx in vec.vocabulary_.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f9776",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3304d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_bigrams = words_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581fda16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=map(list,zip(*top_n_bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3f3dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.barplot(x=y,y=x)\n",
    "plt.title('ngram exploration', fontsize=20)\n",
    "plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a89b837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2e35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic modeling exploration with pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b492cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "stem = PorterStemmer()\n",
    "lem = WordNetLemmatizer()\n",
    "for news in text :\n",
    "    words = [w for w in word_to]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3216fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns.str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61a8ec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_word_number_histogram(text):\n",
    "    text.str.split().map(lambda x: len(x)).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af2c490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec7d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab.nouns(women_policy['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f48c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = women_policy['text'].swifter.apply(lambda x : mecab.nouns(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141c83f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_new = stopwords(words, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63543af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c, cw = common_words(words_new, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ae001",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aaf699",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(women_policy['text'].tolist()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e9d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "women_policy['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9b6e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "women_policy['text'].swifter.apply(lambda x : komoran.nouns(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ae520",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(women_policy['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for i in range(len(women_policy['text'])):\n",
    "    word = mecab.nouns(women_policy['text'][i])\n",
    "    word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b1c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for i in range(15):\n",
    "    word = komoran.nouns(women_policy['text'][i])\n",
    "    word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90f2325",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_word_list = np.concatenate(word_list).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a93d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [n for n in new_word_list if len(n) > 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a4de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_new = stopwords(words, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9935df",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440061a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c, cw = common_words(words_new, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16397ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "= np.concatenate(word_list).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(women_policy['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe112e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = komoran.nouns(women_policy['text'][0])\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942d8bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "women_policy['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9818b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "komoran.pos(women_policy['text'].tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
